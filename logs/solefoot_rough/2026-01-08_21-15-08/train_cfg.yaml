actor_idx_record: 0
algorithm:
  class_name: PPO
  clip_param: 0.2
  desired_kl: 0.01
  encoder_learning_rate: 0.001
  entropy_coef: 0.01
  gamma: 0.99
  lam: 0.95
  learning_rate: 0.001
  max_grad_norm: 1.0
  num_learning_epochs: 5
  num_mini_batches: 4
  schedule: adaptive
  use_clipped_value_loss: true
  value_loss_coef: 1.0
camera_offset:
- 0
- -2
- 0
camera_rotation:
- 0
- 0
- 90
empirical_normalization: false
env_idx_record: 0
fps: 50
frame_size:
- 1280
- 720
init_member_classes: {}
num_steps_per_env: 24
policy:
  actor:
    activation: elu
    class_name: ParitialObsEncodedMlpActor
    hidden_dims:
    - 512
    - 256
    - 128
    init_noise_std: 1.0
  critic:
    activation: elu
    class_name: MlpCritic
    hidden_dims:
    - 512
    - 256
    - 128
record_interval: 50
record_length: 200
rigid_body_idx_record: 0
run_name: ''
runner:
  experiment_name: solefoot_rough
  max_iterations: 10000
  run_name: 2026-01-08_21-15-08
runner_class_name: OnPolicyRunner
save_interval: 500
seed: 1
update_model: false
video: false
wandb_project: solefoot_rough
